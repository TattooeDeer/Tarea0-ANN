{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "\n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>\n",
    "\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"images/IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "\n",
    "    <i><h2 style=\"font-family:serif;font-size:300%; text-align:center;color:#283A5B\"> Tarea 0</h2></i>\n",
    "    <h1 style=\"font-family:serif;font-size:200%; text-align:center;color:#4d4d4d\"> <i> Redes Neuronales Artificiales - San Joaquín </i></h1>\n",
    "    <h3 style = 'font-family:serif;font-size:120%'><i> Ignacio Loayza C. 201273604-8</i></h3>\n",
    "\n",
    "</center>\n",
    "\n",
    "<p>\n",
    "<center>_Marzo 2018_ </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "p {\n",
       "    color: black;\n",
       "    font-family: Serif;\n",
       "    font-size: 1.23em;\n",
       "}\n",
       ".output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "%matplotlib inline\n",
    "\n",
    "# semilla\n",
    "seed = hash(\"Ñanculef es mi pastor, nada me ha de faltar\")%2^32\n",
    "\n",
    "# Imports\n",
    "\n",
    "#Neural Networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# Numerico\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Metricas\n",
    "\n",
    "#Graficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set_style(\"darkgrid\")\n",
    "import graphviz\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Shallow copy\n",
    "import copy\n",
    "\n",
    "#preprocesamiento\n",
    "\n",
    "\n",
    "#HTML incrustation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "p {\n",
    "    color: black;\n",
    "    font-family: Serif;\n",
    "    font-size: 1.23em;\n",
    "}\n",
    ".output_png {\n",
    "        display: table-cell;\n",
    "        text-align: center;\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "</style>\n",
    "\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h2 style=\"font-family:serif;font-size:260%; text-align:center;color:#004d80\"> Back-propagation from Scratch</h2></i>\n",
    "\n",
    "<i><h3 style=\"font-family:serif;font-size:200%; text-align:left;color:#4d4d4d\"> I) Entrenando una red FF mediante Back-propagation</h3></i>\n",
    "\n",
    "Comenzaremos entrenando una red del tipo *Feed Forward* con arquitectura de dos capas ocultas, distribuidas de la forma  32:16 neuronas en las capas y *K* neuronas de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clases necesarias\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, n_inputs, neurons_each_layer, n_outputs):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.neurons_each_layer = neurons_each_layer\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        # Inicializacion de las capas\n",
    "        layers_array = []\n",
    "        index = 0\n",
    "        n_neurons_prev_layer = 0 # para la capa de input\n",
    "\n",
    "        #input layer\n",
    "        layers_array.append(Layer(n_inputs, 0, index))\n",
    "        n_neurons_prev_layer = n_inputs\n",
    "\n",
    "        #Hidden layers\n",
    "        for layer_conf in neurons_each_layer:\n",
    "            index+=1\n",
    "            layers_array.append(Layer(layer_conf, n_neurons_prev_layer,index))\n",
    "            n_neurons_prev_layer = layer_conf\n",
    "        ## Aqui agregar la posibilidad de indicar funciones de transferencia para las capas\n",
    "        \n",
    "        #Output layer\n",
    "        layers_array.append(Layer(n_outputs, n_neurons_prev_layer, index))\n",
    "        self.hidden_layers = layers_array\n",
    "            \n",
    "    ############# Getters & Setters ###########################    \n",
    "    def get_weights_matrix(self, layer_index):\n",
    "        return self.hidden_layers[layer_index].get_weights_matrix()\n",
    "    \n",
    "    def get_n_inputs(self):\n",
    "        return self.n_inputs\n",
    "    def get_neurons_each_layer(self):\n",
    "        return self.neurons_each_layer\n",
    "    def get_n_outputs(self):\n",
    "        return self.n_outputs\n",
    "\n",
    "    def get_network_parameters(self):\n",
    "        network_params = {'n_inputs':self.n_inputs,\n",
    "                        'neurons_each_layer':self.neurons_each_layer,\n",
    "                        'n_outputs':self.n_outputs,\n",
    "                         'hidden_layers':self.hidden_layers}\n",
    "        return network_params\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    def forward_propagate(self, data_row):\n",
    "        previous_activations = np.ones((self.n_inputs,1))\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            if(layer.get_index() == 0):#Si es la primera capa le tenemos que pasar la data_column como las activaciones\n",
    "                layer.compute_layer_activations(data_row)\n",
    "                previous_activations = layer.get_activations_column()\n",
    "            else:\n",
    "                layer.compute_layer_activations(previous_activations)\n",
    "                previous_activations = layer.get_activations_column()\n",
    "                \n",
    "    def backward_pass(self, expected_predictions):\n",
    "        # Primero calculamos el error para cada neurona de la capa de output\n",
    "        # Para calcular la señal de error de la capa de output lo hacemos con respecto a la\n",
    "        # fila de datos\n",
    "        previous_errors = self.calculate_output_error(expected_predictions)\n",
    "        previous_weights = np.ones((self.get_n_outputs(), self.get_n_outputs()))\n",
    "        \n",
    "        for layer in self.hidden_layers[:0:-1]:\n",
    "                #Si es la capa de output, usamos las predicciones esperadas de salida\n",
    "                # La señal de error de la capa de output es la funcion de error evaluada en las predicciones\n",
    "                # multiplicada por los pesos que llegan a la capa de output\n",
    "                \n",
    "            # calculo de la señal de error\n",
    "            layer.set_error_signals(np.dot(np.transpose(previous_weights),previous_errors))\n",
    "            \n",
    "            previous_errors = layer.get_error_signals()\n",
    "            previous_weights = layer.get_weights_matrix()\n",
    "            \n",
    "            #update de los pesos\n",
    "            layer.update_weights()\n",
    "        return\n",
    "        \n",
    "        \n",
    "        #Usemos el error cuadratico medio (MSE)\n",
    "    def calculate_output_error(self, expected):\n",
    "        return self.calculate_loss(expected)*self.hidden_layers[-1].transfer_derivative(self.hidden_layers[-1].get_activations_column())\n",
    "    \n",
    "    def calculate_loss(self, expected): \n",
    "        predicted = self.hidden_layers[-1].get_activations_column()\n",
    "        return np.power(expected - predicted,2)/2\n",
    "    \n",
    "    def gradient_loss(self, expected):\n",
    "        predicted = self.hidden_layers[-1].get_activations_column()\n",
    "        return predicted - expected\n",
    "                \n",
    "        \n",
    "\n",
    "    def train(self, df_train, df_validate):\n",
    "        #Chequear si el numero de atributos concuerda con el numero de inputs especificados\n",
    "        if(len(df_train.columns) != self.n_inputs):\n",
    "            print('El número de columnas del dataset no coincide con el número de inputs especificado para esta red')\n",
    "            print(\"Número de columnas del dataset: %d\" %len(df_train.columns))\n",
    "            print(\"Número de inputs aceptados por la red: %d\" %self.n_inputs)\n",
    "            return\n",
    "        \n",
    "        for index, train_row in df_train.iterrows():\n",
    "            # extraer una fila y forward propagate\n",
    "            self.forward_propagate(train_row)\n",
    "            \n",
    "            # backprop = backward pass + update weights\n",
    "            self.backward_pass(df_validate[index])\n",
    "        return\n",
    "\n",
    "    def predict(self, X_train):\n",
    "        self.forward_propagate(X_train)\n",
    "        predicted = self.hidden_layers[-1].transfer(self.hidden_layers[-1].get_activations_column())\n",
    "        return predicted\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Layer:\n",
    "    def __init__(self, neurons_in_layer, neurons_previous_layer, index, **kargs):\n",
    "        self.layer_index = index\n",
    "        self.neurons_in_layer = neurons_in_layer\n",
    "        self.activations_column = np.zeros((self.neurons_in_layer, 1))\n",
    "        self.error_signals = np.zeros((self.neurons_in_layer,1))\n",
    "        \n",
    "        #Funciones de transferencia disponibles para la capa\n",
    "        if('transfer_func' in kargs):\n",
    "            if(kargs['transfer_func'] == 'sigmoid'):\n",
    "                self.transfer = self.sigmoid\n",
    "                self.transfer_derivative = self.sigmoid_derivative\n",
    "            elif(kargs['transfer_func'] == 'softmax'):\n",
    "                self.transfer = self.softmax\n",
    "                self.transfer_derivative = self.softmax_derivative\n",
    "            elif(kargs['transfer_func'] == 'lineal' or index == 0): #Si es la capa de inputs le damos transferencia lineal\n",
    "                self.transfer = self.linear\n",
    "                self.transfer_derivative = self.linear_derivative\n",
    "        elif(index == 0):# La primera capa es la capa de input, con transferencia lineal\n",
    "            self.transfer = self.linear\n",
    "            self.transfer_derivative = self.linear_derivative\n",
    "        else:# Si no se especifica una funcion de transferencia usaremos por defecto la sigmoidal\n",
    "            self.transfer = self.sigmoid\n",
    "            self.transfer_derivative = self.sigmoid_derivative\n",
    "            \n",
    "        if('learning_rate' in kargs):\n",
    "            self.set_learning_rate(kargs['learning_rate'])\n",
    "        else:# Si no se especifica learning_rate el defecto es 0.01\n",
    "            self.set_learning_rate(0.01)\n",
    "            \n",
    "        #Si es la primera capa no tiene matriz de pesos\n",
    "        if(self.layer_index == 0):\n",
    "            self.weights_matrix = np.identity(self.neurons_in_layer)\n",
    "            #Con esto logramos una matriz identidad que al ser multiplicada por el vector de inputs\n",
    "            #nos da el mismo vector de inputs\n",
    "        else:\n",
    "            self.weights_matrix = np.random.rand(self.neurons_in_layer, neurons_previous_layer)\n",
    "    \n",
    "    def compute_layer_activations(self, activations_prev_layer):\n",
    "        \n",
    "        #Primero calculamos el input_sum, a la capa de input hay que simplemente pasarle la primera fila\n",
    "        #de los datos como 'activations_prev_layer' cuando se entrene la red\n",
    "        self.input_sum = np.dot(self.get_weights_matrix(), activations_prev_layer)\n",
    "        \n",
    "        #Ahora que calculamos el input sum, hay que pasar el resultado por la función de transferencia para ver\n",
    "        #que es lo que las neuronas estan escupiendo\n",
    "        \n",
    "        self.activations_column = [self.transfer(activ_weights_sum) for activ_weights_sum in self.input_sum]\n",
    "        #listo :V\n",
    "\n",
    "    def update_weights(self):\n",
    "        self.set_weights_matrix(\n",
    "            self.get_weights_matrix() - np.dot(np.transpose(self.get_learning_rate()), self.get_error_signals())\n",
    "        )\n",
    "        \n",
    "    ###### Funciones de activacion #########\n",
    "    \n",
    "    # Sigmoid\n",
    "    def sigmoid(self, activation):\n",
    "        TOL = 1e-12 #La sigmoidal se agila en los extremos asi que hay que ponerle un limite de tolerancia\n",
    "        print(activation)\n",
    "        try:\n",
    "            if(activation > 0):\n",
    "                activ = np.maximum(TOL, activation)\n",
    "            elif(activation < 0):\n",
    "                activ = np.maximum(-100,activation)\n",
    "        except TypeError:\n",
    "            activation = activation[0]\n",
    "            if(activation > 0):\n",
    "                activ = np.maximum(TOL, activation)\n",
    "            elif(activation < 0):\n",
    "                activ = np.maximum(-100,activation)\n",
    "        return 1 / (1 + np.exp(-activ))\n",
    "    \n",
    "    def sigmoid_derivative(self, input_sum):\n",
    "        return self.sigmoid(input_sum)*(1.0 - self.sigmoid(input_sum))\n",
    "    \n",
    "    # SoftMax\n",
    "    def softmax(self, activation):\n",
    "        return exp(activation)/np.sum(map(exp, self.activations_column))\n",
    "    def softmax_derivative(self, input_sum):\n",
    "        return self.softmax(input_sum)(1.0 - self.softmax(input_sum))\n",
    "        \n",
    "    # Linear\n",
    "    def linear(self, activation):\n",
    "        return activation\n",
    "    def linear_derivative(self, input_sum):\n",
    "        return 1.0\n",
    "    \n",
    "    ########################################\n",
    "    def get_parameters(self):\n",
    "        layer_params = {'neurons_in_layer':self.neurons_in_layer, 'weights_matrix':self.weights_matrix, \n",
    "                        'index':self.layer_index, 'input_sum':self.input_sum, \n",
    "                        'activations_column':self.activations_column}\n",
    "        return layer_params\n",
    "    \n",
    "    def get_weights_matrix(self):\n",
    "        return self.weights_matrix\n",
    "    def set_weights_matrix(self, new_weights):\n",
    "        self.weights_matrix = new_weights\n",
    "    \n",
    "    def get_index(self):\n",
    "        return self.layer_index\n",
    "    \n",
    "    def get_input_sum(self):\n",
    "        return self.input_sum\n",
    "    \n",
    "    def get_activations_column(self):\n",
    "        return self.activations_column\n",
    "    def get_error_signals(self):\n",
    "        return self.error_signals\n",
    "    def set_error_signals(self, signals_column):\n",
    "        self.error_signals = np.array([signals_column], ndmin=2)\n",
    "    def set_learning_rate(self,learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "    def get_learning_rate(self):\n",
    "        return self.learning_rate\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "a = pd.DataFrame(X_train)\n",
    "b = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': [<__main__.Layer at 0x11fe9bdd8>,\n",
       "  <__main__.Layer at 0x11fe9bbe0>,\n",
       "  <__main__.Layer at 0x11fe9b400>,\n",
       "  <__main__.Layer at 0x11fe9bb70>],\n",
       " 'n_inputs': 4,\n",
       " 'n_outputs': 1,\n",
       " 'neurons_each_layer': (3, 2)}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet = Network(4,(3,2), 1)\n",
    "mynet.get_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.38669831,  0.67591098,  0.43042764,  0.3432941 ],\n",
       "         [ 0.16790954,  0.04328029,  0.71381609,  0.73440091],\n",
       "         [ 0.41888787,  0.16408528,  0.64073374,  0.24678112]],\n",
       "\n",
       "        [[ 0.38651014,  0.6757228 ,  0.43023946,  0.34310593],\n",
       "         [ 0.16772136,  0.04309211,  0.71362791,  0.73421274],\n",
       "         [ 0.4186997 ,  0.1638971 ,  0.64054557,  0.24659294]],\n",
       "\n",
       "        [[ 0.38660411,  0.67581678,  0.43033344,  0.3431999 ],\n",
       "         [ 0.16781534,  0.04318609,  0.71372189,  0.73430671],\n",
       "         [ 0.41879367,  0.16399108,  0.64063954,  0.24668692]]]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.get_weights_matrix(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.01000914873\n",
      "2.15494417438\n",
      "3.65791190007\n",
      "1.34507417405\n",
      "2.13516622472\n",
      "0.563793648328\n",
      "[0.63732986210291354]\n",
      "[0.63732986210291354]\n"
     ]
    }
   ],
   "source": [
    "mynet.train(a[:1:], b[:1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41492982,  0.26149109]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.get_weights_matrix(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_net =  mynet.get_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = dict_net['hidden_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[3].get_activations_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=layers[2].get_parameters()['weights_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17931575,  0.00422472,  0.86817085],\n",
       "       [ 0.34906061,  0.28057365,  0.97737766]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_row = np.ones((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mynet.forward_propagate(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ebd609b312c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlineal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "c = [lineal(activation) for activation in b]\n",
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1  3.5  1.4  0.2]\n",
      "0\n",
      "[ 4.9  3.   1.4  0.2]\n",
      "0\n",
      "[ 4.7  3.2  1.3  0.2]\n",
      "0\n",
      "[ 4.6  3.1  1.5  0.2]\n",
      "0\n",
      "[ 5.   3.6  1.4  0.2]\n",
      "0\n",
      "[ 5.4  3.9  1.7  0.4]\n",
      "0\n",
      "[ 4.6  3.4  1.4  0.3]\n",
      "0\n",
      "[ 5.   3.4  1.5  0.2]\n",
      "0\n",
      "[ 4.4  2.9  1.4  0.2]\n",
      "0\n",
      "[ 4.9  3.1  1.5  0.1]\n",
      "0\n",
      "[ 5.4  3.7  1.5  0.2]\n",
      "0\n",
      "[ 4.8  3.4  1.6  0.2]\n",
      "0\n",
      "[ 4.8  3.   1.4  0.1]\n",
      "0\n",
      "[ 4.3  3.   1.1  0.1]\n",
      "0\n",
      "[ 5.8  4.   1.2  0.2]\n",
      "0\n",
      "[ 5.7  4.4  1.5  0.4]\n",
      "0\n",
      "[ 5.4  3.9  1.3  0.4]\n",
      "0\n",
      "[ 5.1  3.5  1.4  0.3]\n",
      "0\n",
      "[ 5.7  3.8  1.7  0.3]\n",
      "0\n",
      "[ 5.1  3.8  1.5  0.3]\n",
      "0\n",
      "[ 5.4  3.4  1.7  0.2]\n",
      "0\n",
      "[ 5.1  3.7  1.5  0.4]\n",
      "0\n",
      "[ 4.6  3.6  1.   0.2]\n",
      "0\n",
      "[ 5.1  3.3  1.7  0.5]\n",
      "0\n",
      "[ 4.8  3.4  1.9  0.2]\n",
      "0\n",
      "[ 5.   3.   1.6  0.2]\n",
      "0\n",
      "[ 5.   3.4  1.6  0.4]\n",
      "0\n",
      "[ 5.2  3.5  1.5  0.2]\n",
      "0\n",
      "[ 5.2  3.4  1.4  0.2]\n",
      "0\n",
      "[ 4.7  3.2  1.6  0.2]\n",
      "0\n",
      "[ 4.8  3.1  1.6  0.2]\n",
      "0\n",
      "[ 5.4  3.4  1.5  0.4]\n",
      "0\n",
      "[ 5.2  4.1  1.5  0.1]\n",
      "0\n",
      "[ 5.5  4.2  1.4  0.2]\n",
      "0\n",
      "[ 4.9  3.1  1.5  0.1]\n",
      "0\n",
      "[ 5.   3.2  1.2  0.2]\n",
      "0\n",
      "[ 5.5  3.5  1.3  0.2]\n",
      "0\n",
      "[ 4.9  3.1  1.5  0.1]\n",
      "0\n",
      "[ 4.4  3.   1.3  0.2]\n",
      "0\n",
      "[ 5.1  3.4  1.5  0.2]\n",
      "0\n",
      "[ 5.   3.5  1.3  0.3]\n",
      "0\n",
      "[ 4.5  2.3  1.3  0.3]\n",
      "0\n",
      "[ 4.4  3.2  1.3  0.2]\n",
      "0\n",
      "[ 5.   3.5  1.6  0.6]\n",
      "0\n",
      "[ 5.1  3.8  1.9  0.4]\n",
      "0\n",
      "[ 4.8  3.   1.4  0.3]\n",
      "0\n",
      "[ 5.1  3.8  1.6  0.2]\n",
      "0\n",
      "[ 4.6  3.2  1.4  0.2]\n",
      "0\n",
      "[ 5.3  3.7  1.5  0.2]\n",
      "0\n",
      "[ 5.   3.3  1.4  0.2]\n",
      "0\n",
      "[ 7.   3.2  4.7  1.4]\n",
      "1\n",
      "[ 6.4  3.2  4.5  1.5]\n",
      "1\n",
      "[ 6.9  3.1  4.9  1.5]\n",
      "1\n",
      "[ 5.5  2.3  4.   1.3]\n",
      "1\n",
      "[ 6.5  2.8  4.6  1.5]\n",
      "1\n",
      "[ 5.7  2.8  4.5  1.3]\n",
      "1\n",
      "[ 6.3  3.3  4.7  1.6]\n",
      "1\n",
      "[ 4.9  2.4  3.3  1. ]\n",
      "1\n",
      "[ 6.6  2.9  4.6  1.3]\n",
      "1\n",
      "[ 5.2  2.7  3.9  1.4]\n",
      "1\n",
      "[ 5.   2.   3.5  1. ]\n",
      "1\n",
      "[ 5.9  3.   4.2  1.5]\n",
      "1\n",
      "[ 6.   2.2  4.   1. ]\n",
      "1\n",
      "[ 6.1  2.9  4.7  1.4]\n",
      "1\n",
      "[ 5.6  2.9  3.6  1.3]\n",
      "1\n",
      "[ 6.7  3.1  4.4  1.4]\n",
      "1\n",
      "[ 5.6  3.   4.5  1.5]\n",
      "1\n",
      "[ 5.8  2.7  4.1  1. ]\n",
      "1\n",
      "[ 6.2  2.2  4.5  1.5]\n",
      "1\n",
      "[ 5.6  2.5  3.9  1.1]\n",
      "1\n",
      "[ 5.9  3.2  4.8  1.8]\n",
      "1\n",
      "[ 6.1  2.8  4.   1.3]\n",
      "1\n",
      "[ 6.3  2.5  4.9  1.5]\n",
      "1\n",
      "[ 6.1  2.8  4.7  1.2]\n",
      "1\n",
      "[ 6.4  2.9  4.3  1.3]\n",
      "1\n",
      "[ 6.6  3.   4.4  1.4]\n",
      "1\n",
      "[ 6.8  2.8  4.8  1.4]\n",
      "1\n",
      "[ 6.7  3.   5.   1.7]\n",
      "1\n",
      "[ 6.   2.9  4.5  1.5]\n",
      "1\n",
      "[ 5.7  2.6  3.5  1. ]\n",
      "1\n",
      "[ 5.5  2.4  3.8  1.1]\n",
      "1\n",
      "[ 5.5  2.4  3.7  1. ]\n",
      "1\n",
      "[ 5.8  2.7  3.9  1.2]\n",
      "1\n",
      "[ 6.   2.7  5.1  1.6]\n",
      "1\n",
      "[ 5.4  3.   4.5  1.5]\n",
      "1\n",
      "[ 6.   3.4  4.5  1.6]\n",
      "1\n",
      "[ 6.7  3.1  4.7  1.5]\n",
      "1\n",
      "[ 6.3  2.3  4.4  1.3]\n",
      "1\n",
      "[ 5.6  3.   4.1  1.3]\n",
      "1\n",
      "[ 5.5  2.5  4.   1.3]\n",
      "1\n",
      "[ 5.5  2.6  4.4  1.2]\n",
      "1\n",
      "[ 6.1  3.   4.6  1.4]\n",
      "1\n",
      "[ 5.8  2.6  4.   1.2]\n",
      "1\n",
      "[ 5.   2.3  3.3  1. ]\n",
      "1\n",
      "[ 5.6  2.7  4.2  1.3]\n",
      "1\n",
      "[ 5.7  3.   4.2  1.2]\n",
      "1\n",
      "[ 5.7  2.9  4.2  1.3]\n",
      "1\n",
      "[ 6.2  2.9  4.3  1.3]\n",
      "1\n",
      "[ 5.1  2.5  3.   1.1]\n",
      "1\n",
      "[ 5.7  2.8  4.1  1.3]\n",
      "1\n",
      "[ 6.3  3.3  6.   2.5]\n",
      "2\n",
      "[ 5.8  2.7  5.1  1.9]\n",
      "2\n",
      "[ 7.1  3.   5.9  2.1]\n",
      "2\n",
      "[ 6.3  2.9  5.6  1.8]\n",
      "2\n",
      "[ 6.5  3.   5.8  2.2]\n",
      "2\n",
      "[ 7.6  3.   6.6  2.1]\n",
      "2\n",
      "[ 4.9  2.5  4.5  1.7]\n",
      "2\n",
      "[ 7.3  2.9  6.3  1.8]\n",
      "2\n",
      "[ 6.7  2.5  5.8  1.8]\n",
      "2\n",
      "[ 7.2  3.6  6.1  2.5]\n",
      "2\n",
      "[ 6.5  3.2  5.1  2. ]\n",
      "2\n",
      "[ 6.4  2.7  5.3  1.9]\n",
      "2\n",
      "[ 6.8  3.   5.5  2.1]\n",
      "2\n",
      "[ 5.7  2.5  5.   2. ]\n",
      "2\n",
      "[ 5.8  2.8  5.1  2.4]\n",
      "2\n",
      "[ 6.4  3.2  5.3  2.3]\n",
      "2\n",
      "[ 6.5  3.   5.5  1.8]\n",
      "2\n",
      "[ 7.7  3.8  6.7  2.2]\n",
      "2\n",
      "[ 7.7  2.6  6.9  2.3]\n",
      "2\n",
      "[ 6.   2.2  5.   1.5]\n",
      "2\n",
      "[ 6.9  3.2  5.7  2.3]\n",
      "2\n",
      "[ 5.6  2.8  4.9  2. ]\n",
      "2\n",
      "[ 7.7  2.8  6.7  2. ]\n",
      "2\n",
      "[ 6.3  2.7  4.9  1.8]\n",
      "2\n",
      "[ 6.7  3.3  5.7  2.1]\n",
      "2\n",
      "[ 7.2  3.2  6.   1.8]\n",
      "2\n",
      "[ 6.2  2.8  4.8  1.8]\n",
      "2\n",
      "[ 6.1  3.   4.9  1.8]\n",
      "2\n",
      "[ 6.4  2.8  5.6  2.1]\n",
      "2\n",
      "[ 7.2  3.   5.8  1.6]\n",
      "2\n",
      "[ 7.4  2.8  6.1  1.9]\n",
      "2\n",
      "[ 7.9  3.8  6.4  2. ]\n",
      "2\n",
      "[ 6.4  2.8  5.6  2.2]\n",
      "2\n",
      "[ 6.3  2.8  5.1  1.5]\n",
      "2\n",
      "[ 6.1  2.6  5.6  1.4]\n",
      "2\n",
      "[ 7.7  3.   6.1  2.3]\n",
      "2\n",
      "[ 6.3  3.4  5.6  2.4]\n",
      "2\n",
      "[ 6.4  3.1  5.5  1.8]\n",
      "2\n",
      "[ 6.   3.   4.8  1.8]\n",
      "2\n",
      "[ 6.9  3.1  5.4  2.1]\n",
      "2\n",
      "[ 6.7  3.1  5.6  2.4]\n",
      "2\n",
      "[ 6.9  3.1  5.1  2.3]\n",
      "2\n",
      "[ 5.8  2.7  5.1  1.9]\n",
      "2\n",
      "[ 6.8  3.2  5.9  2.3]\n",
      "2\n",
      "[ 6.7  3.3  5.7  2.5]\n",
      "2\n",
      "[ 6.7  3.   5.2  2.3]\n",
      "2\n",
      "[ 6.3  2.5  5.   1.9]\n",
      "2\n",
      "[ 6.5  3.   5.2  2. ]\n",
      "2\n",
      "[ 6.2  3.4  5.4  2.3]\n",
      "2\n",
      "[ 5.9  3.   5.1  1.8]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "a = pd.DataFrame(X_train)\n",
    "b = pd.DataFrame(y_train)\n",
    "for index, row in a.iterrows():\n",
    "    print(np.array(row))\n",
    "    print(np.array(y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
